{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/vijay/Desktop/SmitMaurya/HybridModel/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import itertools\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "from src.util import load_samples\n",
    "from src.data.data_collator import LegalDataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST2025_EN_PATH = \"data/COLIEE2025statute_data-English/train/R05_en.xml\"\n",
    "\n",
    "SELECTED_ID = \"R05\"\n",
    "\n",
    "RAW_DATA_DIR = \"data\"\n",
    "DATA_OUTPUT_DIR = \"data/synthesys\"\n",
    "QUERY_PATH = os.path.join(RAW_DATA_DIR, \"COLIEE2025statute_data-English/train\")\n",
    "ARTICLE_PATH = os.path.join(RAW_DATA_DIR, \"full_en_civil_code_df_24.csv\")\n",
    "\n",
    "CHECKPOINT_DIR = \"checkpoints\"\n",
    "STEP1_CHECKPOINT_DIR = f\"{CHECKPOINT_DIR}/step1_bge_pre_retrieval\"\n",
    "STEP2_CHECKPOINT_DIR = f\"{CHECKPOINT_DIR}/step2_rankllama_retrieval\"\n",
    "STEP3_CHECKPOINT_DIR = f\"{CHECKPOINT_DIR}/step3_final_retrieval\"\n",
    "\n",
    "ACCEPTED_MODELS = [\n",
    "    \"e5_mistral_7b_instruct\",\n",
    "    \"gemma_2_9b_it\",\n",
    "    \"gemma_2_27b_it\",\n",
    "    \"phi_3_medium_4k_instruct\",\n",
    "]\n",
    "\n",
    "\n",
    "# TODO: fix bug\n",
    "BUG_ARTICLE_POSTFIX = \"(1)\"  # In the R04's task 3 label, there are some ground truth labels having \"(1)\" postfix. We need to remove them.\n",
    "\n",
    "\n",
    "INFERENCE_DIR = \"checkpoints/inference\"\n",
    "\n",
    "\n",
    "# Step 1\n",
    "BGE_TOP = 100\n",
    "BGE_SEQUENCE_MAX_LENGTH = 1024\n",
    "HISTOGRAM_N_POSITIVE_REPLICATES = 300\n",
    "\n",
    "\n",
    "# Step 2\n",
    "RANKLLAMA_MAX_LENGTH = 1024\n",
    "RANKLLAMA_THRESHOLD = -3.5  # preserve about 50 candidates for each query\n",
    "RANKLLAMA_TOP = 50\n",
    "\n",
    "\n",
    "# Step 4\n",
    "CUT_OFF_THRESHOLD = 0.3687529996711829\n",
    "WEIGHTS = np.array([0.23716786, 0.21487627, 0.3068145 , 0.24114137])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23716786, 0.21487627, 0.3068145 , 0.24114137])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEIGHTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load data\n",
    "# Load the article data\n",
    "en_article_df = pd.read_csv(ARTICLE_PATH)\n",
    "en_article_df.rename(columns={\"article\": \"article_id\", \"content\": \"article_content\"}, inplace=True)\n",
    "\n",
    "# Load the query data\n",
    "query_files = glob.glob(f\"{QUERY_PATH}/*.xml\")\n",
    "\n",
    "queries = []\n",
    "for query_file in query_files:\n",
    "    queries += load_samples(query_file)\n",
    "\n",
    "en_query_df = pd.DataFrame(queries)\n",
    "en_query_df = en_query_df.rename(columns={\"index\": \"query_id\",\n",
    "                                          \"content\": \"query_content\",\n",
    "                                          \"result\": \"task3_label\",\n",
    "                                          \"label\": \"task4_label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_df = en_query_df[en_query_df[\"query_id\"].str.startswith(SELECTED_ID)].copy(deep=True)\n",
    "\n",
    "del en_query_df\n",
    "\n",
    "if len(test_query_df) == 0:\n",
    "    queries = load_samples(TEST2025_EN_PATH)\n",
    "\n",
    "    test_query_df = pd.DataFrame(queries)\n",
    "    test_query_df = test_query_df.rename(columns={\"index\": \"query_id\",\n",
    "                                                    \"content\": \"query_content\",\n",
    "                                                    \"result\": \"task3_label\",\n",
    "                                                    \"label\": \"task4_label\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"task3_label\" in test_query_df.columns:\n",
    "    test_query_df = test_query_df.drop(columns=[\"task3_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: BGE Pre-retrieval\n",
    "\n",
    "### 1.1. BGE Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 29739.81it/s]\n",
      "pre tokenize: 100%|██████████| 24/24 [00:00<00:00, 322.82it/s]\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Inference Embeddings: 100%|██████████| 24/24 [00:00<00:00, 33.19it/s]\n",
      "pre tokenize: 100%|██████████| 3/3 [00:00<00:00, 284.96it/s]\n",
      "Inference Embeddings: 100%|██████████| 3/3 [00:00<00:00, 62.49it/s]\n"
     ]
    }
   ],
   "source": [
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True, device='cuda')\n",
    "\n",
    "# article embedding\n",
    "article_embeddings = model.encode(en_article_df[\"article_content\"].tolist(),\n",
    "                                  batch_size=32,\n",
    "                                  max_length=BGE_SEQUENCE_MAX_LENGTH\n",
    "                                  )['dense_vecs']\n",
    "\n",
    "\n",
    "# query embedding\n",
    "query_embeddings = model.encode(test_query_df[\"query_content\"].tolist(),\n",
    "                                batch_size=32,\n",
    "                                max_length=BGE_SEQUENCE_MAX_LENGTH\n",
    "                                )['dense_vecs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_embedding_dict = dict(zip(en_article_df[\"article_id\"].tolist(), article_embeddings))\n",
    "query_embedding_dict = dict(zip(test_query_df[\"query_id\"].tolist(), query_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Retrieval with Histogram-based Gradient Boosting\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(query_id, labels):\n",
    "    return list(itertools.product([query_id], labels))\n",
    "\n",
    "\n",
    "def distance_function(query_emb, article_emb):\n",
    "    return query_emb - article_emb\n",
    "\n",
    "\n",
    "def get_distance(query_id, article_id, query_embedding_dict, article_embedding_dict):\n",
    "    query_emb = query_embedding_dict[query_id]\n",
    "    article_emb = article_embedding_dict[article_id]\n",
    "\n",
    "    return distance_function(query_emb, article_emb)\n",
    "\n",
    "\n",
    "query_article_pairs = test_query_df.apply(lambda x: make_pairs(x[\"query_id\"], en_article_df[\"article_id\"].values), axis=1)\n",
    "query_article_pairs = sum(query_article_pairs, [])\n",
    "\n",
    "X_test = list(map(lambda x: get_distance(*x, query_embedding_dict, article_embedding_dict), query_article_pairs))\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_preds(group):\n",
    "    group = group.sort_values(\"step1_score\", ascending=False)\n",
    "\n",
    "    # cut_off_score = group.iloc[BGE_TOP][\"step1_score\"]\n",
    "    # group[\"keep\"] = group[\"step1_score\"] > cut_off_score - 1e-5\n",
    "\n",
    "    group[\"keep\"] = False\n",
    "    group.iloc[:BGE_TOP, group.columns.get_loc(\"keep\")] = True\n",
    "\n",
    "    return group\n",
    "\n",
    "\n",
    "model = joblib.load(open(f\"{STEP1_CHECKPOINT_DIR}/histogram_classifier.pkl\", \"rb\"))\n",
    "y_pred = model.predict_proba(X_test)\n",
    "\n",
    "test_df_step1 = pd.DataFrame(query_article_pairs, columns=[\"query_id\", \"article_id\"])\n",
    "test_df_step1[\"step1_score\"] = y_pred[:, 1]\n",
    "\n",
    "test_df_step1 = test_df_step1.groupby(\"query_id\")[test_df_step1.columns.tolist()]\\\n",
    "                             .apply(get_top_preds)\\\n",
    "                             .reset_index(drop=True)\n",
    "\n",
    "test_df_step1 = test_df_step1[test_df_step1[\"keep\"] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: RankLlama for 2nd-stage retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(peft_model_name):\n",
    "    config = PeftConfig.from_pretrained(peft_model_name)\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(config.base_model_name_or_path,\n",
    "                                                                    num_labels=1,\n",
    "                                                                    torch_dtype=torch.bfloat16,\n",
    "                                                                    device_map=\"auto\")\n",
    "    model = PeftModel.from_pretrained(base_model, peft_model_name)\n",
    "    model = model.merge_and_unload()\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_prompt(query, title, passage):\n",
    "    return f'query: {query}<s>document: {title} {passage}'\n",
    "\n",
    "\n",
    "def get_scores(model, tokenizer, df, batch_size, max_len, data_collator):\n",
    "    scores = []\n",
    "\n",
    "    for i in tqdm(range(0, len(df), batch_size)):\n",
    "        batch = df[i:i+batch_size]\n",
    "\n",
    "        text = batch.apply(lambda x: make_prompt(x['query_content'], x['article_id'], x['article_content']), axis=1)\n",
    "        text = list(text)\n",
    "\n",
    "        inputs = tokenizer(text, max_length=max_len, truncation=True)\n",
    "        inputs = [dict(zip(inputs.keys(), values)) for values in zip(*inputs.values())]  # convert to list of dicts\n",
    "\n",
    "        inputs = data_collator(inputs)\n",
    "        inputs = inputs.to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        scores.extend(logits.tolist())\n",
    "\n",
    "    return np.array(scores).squeeze().tolist()\n",
    "\n",
    "\n",
    "def get_top_preds(group):\n",
    "    group = group.sort_values(\"step2_score\", ascending=False)\n",
    "\n",
    "    cut_off_score = group.iloc[RANKLLAMA_TOP][\"step2_score\"]\n",
    "    group[\"keep\"] = group[\"step2_score\"] > cut_off_score - 1e-5\n",
    "\n",
    "    return group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-2-7b-hf and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and model\n",
    "model = get_model('castorini/rankllama-v1-7b-lora-passage')\n",
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-2-7b-hf')\n",
    "\n",
    "tokenizer.pad_token = \"<unk>\"\n",
    "model.config.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/519 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 519/519 [07:41<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "data_collator = LegalDataCollatorWithPadding(tokenizer)\n",
    "\n",
    "test_df_step2 = test_df_step1.copy(deep=True)\n",
    "test_df_step2 = test_df_step2.merge(test_query_df[[\"query_id\", \"query_content\"]], how=\"left\")\n",
    "test_df_step2 = test_df_step2.merge(en_article_df[[\"article_id\", \"article_content\"]], how=\"left\")\n",
    "\n",
    "test_step2_scores = get_scores(model, tokenizer, test_df_step2, 16, RANKLLAMA_MAX_LENGTH, data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df_step2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_df_step2\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_df_step2' is not defined"
     ]
    }
   ],
   "source": [
    "test_df_step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_step2_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_step2_scores\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_step2_scores' is not defined"
     ]
    }
   ],
   "source": [
    "test_step2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_step2[\"step2_score\"] = test_step2_scores\n",
    "test_df_step2 = test_df_step2.groupby(\"query_id\")[test_df_step2.columns.tolist()]\\\n",
    "                             .apply(get_top_preds)\\\n",
    "                             .reset_index(drop=True)\n",
    "\n",
    "test_df_step2 = test_df_step2[test_df_step2[\"keep\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_step2.to_json(f\"checkpoints/inference/{SELECTED_ID}_step2.jsonl\", lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: LLM Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer to run.sh to get the predicted logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_step2 = pd.read_json(f\"checkpoints/inference/{SELECTED_ID}_step2.jsonl\", lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_logits(file_paths):\n",
    "    logits = []\n",
    "    for file_path in file_paths:\n",
    "        preds = np.load(file_path)\n",
    "        preds = softmax(preds, axis=1)\n",
    "\n",
    "        logits.append(preds[:, 1])\n",
    "\n",
    "    return np.array(logits).T\n",
    "\n",
    "\n",
    "all_logit_path = [INFERENCE_DIR + f\"/{SELECTED_ID}eval/\" + model + f\"/{SELECTED_ID}_step2_logits.npy\" for model in ACCEPTED_MODELS]\n",
    "all_logit_path.sort()\n",
    "\n",
    "all_logits = load_logits(all_logit_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: review the top filter\n",
    "def top_filter(group_df):\n",
    "    group_df = group_df.sort_values(by=[\"step3_score\"],\n",
    "                                          ascending=False,\n",
    "                                          ignore_index=True)\n",
    "    return group_df[:2]\n",
    "\n",
    "\n",
    "def fill_none_predicted(row, step3_top2_df):\n",
    "    if type(row[\"article_id\"]) == list:\n",
    "        return row\n",
    "    row[\"article_id\"] = step3_top2_df[step3_top2_df[\"query_id\"] == row[\"query_id\"]][\"article_id\"].values[0]\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (np.dot(all_logits, WEIGHTS) > CUT_OFF_THRESHOLD).astype(int)\n",
    "\n",
    "test_df_step3 = test_df_step2.copy(deep=True)\n",
    "test_df_step3[\"keep\"] = preds & (test_df_step3[\"step2_score\"] > RANKLLAMA_THRESHOLD)\n",
    "test_df_step3 = test_df_step3[test_df_step3[\"keep\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>step1_score</th>\n",
       "      <th>keep</th>\n",
       "      <th>query_content</th>\n",
       "      <th>article_content</th>\n",
       "      <th>step2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R05-01-A</td>\n",
       "      <td>537</td>\n",
       "      <td>0.538559</td>\n",
       "      <td>True</td>\n",
       "      <td>The validity of a third party beneficiary cont...</td>\n",
       "      <td>Article 537  (1) If one of the parties promise...</td>\n",
       "      <td>4.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>R05-02-A</td>\n",
       "      <td>713</td>\n",
       "      <td>0.020527</td>\n",
       "      <td>True</td>\n",
       "      <td>Mental capacity means the capacity to apprecia...</td>\n",
       "      <td>Article 713  A person who has inflicted damage...</td>\n",
       "      <td>3.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>R05-02-A</td>\n",
       "      <td>712</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>True</td>\n",
       "      <td>Mental capacity means the capacity to apprecia...</td>\n",
       "      <td>Article 712  If a minor has inflicted damage o...</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>R05-02-A</td>\n",
       "      <td>3-2</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>True</td>\n",
       "      <td>Mental capacity means the capacity to apprecia...</td>\n",
       "      <td>Article 3-2  If the person making a juridical ...</td>\n",
       "      <td>-0.941406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>R05-02-E</td>\n",
       "      <td>526</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>True</td>\n",
       "      <td>If an offeror of a contract comes to be in a c...</td>\n",
       "      <td>Article 526  If an offeror dies, comes to be i...</td>\n",
       "      <td>8.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5373</th>\n",
       "      <td>R05-36-E</td>\n",
       "      <td>705</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>True</td>\n",
       "      <td>A person that has paid money or delivered anyt...</td>\n",
       "      <td>Article 705  A person that has paid money or d...</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>R05-36-I</td>\n",
       "      <td>466-5</td>\n",
       "      <td>0.938789</td>\n",
       "      <td>True</td>\n",
       "      <td>A special agreement to restrict assignment mad...</td>\n",
       "      <td>Article 466-5  (1) Notwithstanding the provisi...</td>\n",
       "      <td>7.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>R05-36-I</td>\n",
       "      <td>466-4</td>\n",
       "      <td>0.968195</td>\n",
       "      <td>True</td>\n",
       "      <td>A special agreement to restrict assignment mad...</td>\n",
       "      <td>Article 466-4  (1) The provisions of Article 4...</td>\n",
       "      <td>6.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>R05-36-I</td>\n",
       "      <td>466</td>\n",
       "      <td>0.630611</td>\n",
       "      <td>True</td>\n",
       "      <td>A special agreement to restrict assignment mad...</td>\n",
       "      <td>Article 466  (1) A claim may be assigned; prov...</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5529</th>\n",
       "      <td>R05-36-U</td>\n",
       "      <td>505</td>\n",
       "      <td>0.177583</td>\n",
       "      <td>True</td>\n",
       "      <td>A special agreement to prohibit a set-off made...</td>\n",
       "      <td>Article 505  (1) If two persons bear an obliga...</td>\n",
       "      <td>5.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      query_id article_id  step1_score  keep  \\\n",
       "0     R05-01-A        537     0.538559  True   \n",
       "55    R05-02-A        713     0.020527  True   \n",
       "56    R05-02-A        712     0.001173  True   \n",
       "60    R05-02-A        3-2     0.001198  True   \n",
       "108   R05-02-E        526     0.999860  True   \n",
       "...        ...        ...          ...   ...   \n",
       "5373  R05-36-E        705     0.999874  True   \n",
       "5424  R05-36-I      466-5     0.938789  True   \n",
       "5425  R05-36-I      466-4     0.968195  True   \n",
       "5427  R05-36-I        466     0.630611  True   \n",
       "5529  R05-36-U        505     0.177583  True   \n",
       "\n",
       "                                          query_content  \\\n",
       "0     The validity of a third party beneficiary cont...   \n",
       "55    Mental capacity means the capacity to apprecia...   \n",
       "56    Mental capacity means the capacity to apprecia...   \n",
       "60    Mental capacity means the capacity to apprecia...   \n",
       "108   If an offeror of a contract comes to be in a c...   \n",
       "...                                                 ...   \n",
       "5373  A person that has paid money or delivered anyt...   \n",
       "5424  A special agreement to restrict assignment mad...   \n",
       "5425  A special agreement to restrict assignment mad...   \n",
       "5427  A special agreement to restrict assignment mad...   \n",
       "5529  A special agreement to prohibit a set-off made...   \n",
       "\n",
       "                                        article_content  step2_score  \n",
       "0     Article 537  (1) If one of the parties promise...     4.437500  \n",
       "55    Article 713  A person who has inflicted damage...     3.484375  \n",
       "56    Article 712  If a minor has inflicted damage o...     2.250000  \n",
       "60    Article 3-2  If the person making a juridical ...    -0.941406  \n",
       "108   Article 526  If an offeror dies, comes to be i...     8.875000  \n",
       "...                                                 ...          ...  \n",
       "5373  Article 705  A person that has paid money or d...     7.000000  \n",
       "5424  Article 466-5  (1) Notwithstanding the provisi...     7.312500  \n",
       "5425  Article 466-4  (1) The provisions of Article 4...     6.281250  \n",
       "5427  Article 466  (1) A claim may be assigned; prov...     6.000000  \n",
       "5529  Article 505  (1) If two persons bear an obliga...     5.625000  \n",
       "\n",
       "[141 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_step3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "step3_score_df = test_df_step2.copy(deep=True)\n",
    "step3_score_df[\"step3_score\"] = np.dot(all_logits, WEIGHTS)\n",
    "\n",
    "step3_top2_df = step3_score_df.drop_duplicates(subset=[\"query_id\", \"article_id\"])\\\n",
    "    .groupby(\"query_id\")[step3_score_df.columns]\\\n",
    "    .apply(top_filter)\\\n",
    "    .reset_index(drop=True)\n",
    "step3_top2_df = step3_top2_df.groupby(\"query_id\")[\"article_id\"].apply(list).reset_index()\n",
    "\n",
    "\n",
    "submission_df = test_df_step3.copy(deep=True)\n",
    "submission_df = submission_df.groupby(\"query_id\")[\"article_id\"].apply(list).reset_index()\n",
    "submission_df = submission_df.merge(test_query_df, on=\"query_id\", how=\"right\")\n",
    "\n",
    "\n",
    "# In some cases, we can't find any predicted articles. We need to fill them with the top 2 articles from step 3\n",
    "submission_df = submission_df.apply(lambda x: fill_none_predicted(x, step3_top2_df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_json(f\"{SELECTED_ID}_submission.jsonl\", lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>query_content</th>\n",
       "      <th>task4_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R05-01-A</td>\n",
       "      <td>[537]</td>\n",
       "      <td>The validity of a third party beneficiary cont...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R05-02-A</td>\n",
       "      <td>[713, 712, 3-2]</td>\n",
       "      <td>Mental capacity means the capacity to apprecia...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R05-02-I</td>\n",
       "      <td>[3-2]</td>\n",
       "      <td>If a party to a contract did not have mental c...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R05-02-U</td>\n",
       "      <td>[121-2, 3-2]</td>\n",
       "      <td>If a party to a contract did not have mental c...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R05-02-E</td>\n",
       "      <td>[526, 97]</td>\n",
       "      <td>If an offeror of a contract comes to be in a c...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>R05-36-A</td>\n",
       "      <td>[107]</td>\n",
       "      <td>In the case where an agent performs an act tha...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>R05-36-I</td>\n",
       "      <td>[466-5, 466-4, 466]</td>\n",
       "      <td>A special agreement to restrict assignment mad...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>R05-36-U</td>\n",
       "      <td>[505]</td>\n",
       "      <td>A special agreement to prohibit a set-off made...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>R05-36-E</td>\n",
       "      <td>[705]</td>\n",
       "      <td>A person that has paid money or delivered anyt...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>R05-36-O</td>\n",
       "      <td>[415, 622]</td>\n",
       "      <td>If the lessee has lost the leased thing due to...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_id           article_id  \\\n",
       "0    R05-01-A                [537]   \n",
       "1    R05-02-A      [713, 712, 3-2]   \n",
       "2    R05-02-I                [3-2]   \n",
       "3    R05-02-U         [121-2, 3-2]   \n",
       "4    R05-02-E            [526, 97]   \n",
       "..        ...                  ...   \n",
       "104  R05-36-A                [107]   \n",
       "105  R05-36-I  [466-5, 466-4, 466]   \n",
       "106  R05-36-U                [505]   \n",
       "107  R05-36-E                [705]   \n",
       "108  R05-36-O           [415, 622]   \n",
       "\n",
       "                                         query_content task4_label  \n",
       "0    The validity of a third party beneficiary cont...           Y  \n",
       "1    Mental capacity means the capacity to apprecia...           N  \n",
       "2    If a party to a contract did not have mental c...           Y  \n",
       "3    If a party to a contract did not have mental c...           Y  \n",
       "4    If an offeror of a contract comes to be in a c...           Y  \n",
       "..                                                 ...         ...  \n",
       "104  In the case where an agent performs an act tha...           N  \n",
       "105  A special agreement to restrict assignment mad...           Y  \n",
       "106  A special agreement to prohibit a set-off made...           Y  \n",
       "107  A person that has paid money or delivered anyt...           N  \n",
       "108  If the lessee has lost the leased thing due to...           N  \n",
       "\n",
       "[109 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Aggregate retrieval metrics ===\n",
      "Queries evaluated : 109\n",
      "Mean Precision (full predicted lists) : 0.7385\n",
      "Mean Recall (full predicted lists)    : 0.8532\n",
      "Mean F2 (β=2)                         : 0.8114\n",
      "MAP (all queries; AP=0 for empty)    : 0.8203\n",
      "MAP (only queries with >=1 gold)     : 0.8203\n",
      "\n",
      "Precision@k (k=1..4):\n",
      "  P@1: 0.8073\n",
      "  P@2: 0.4817\n",
      "  P@3: 0.3333\n",
      "  P@4: 0.2523\n",
      "\n",
      "Recall@k (k=1..4):\n",
      "  R@1: 0.7339\n",
      "  R@2: 0.8303\n",
      "  R@3: 0.8486\n",
      "  R@4: 0.8532\n",
      "\n",
      "Top 5 queries by AP:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>n_pred</th>\n",
       "      <th>n_gold</th>\n",
       "      <th>precision_full</th>\n",
       "      <th>recall_full</th>\n",
       "      <th>f2_full</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R05-01-A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R05-02-I</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R05-02-U</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R05-02-E</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R05-03-A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  n_pred  n_gold  precision_full  recall_full   f2_full   AP\n",
       "0  R05-01-A       1       1             1.0          1.0  1.000000  1.0\n",
       "1  R05-02-I       1       1             1.0          1.0  1.000000  1.0\n",
       "2  R05-02-U       2       2             1.0          1.0  1.000000  1.0\n",
       "3  R05-02-E       2       1             0.5          1.0  0.833333  1.0\n",
       "4  R05-03-A       1       1             1.0          1.0  1.000000  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bottom 5 queries by AP (including zero AP):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>n_pred</th>\n",
       "      <th>n_gold</th>\n",
       "      <th>precision_full</th>\n",
       "      <th>recall_full</th>\n",
       "      <th>f2_full</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>R05-20-E</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>R05-19-O</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>R05-27-A</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>R05-26-I</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>R05-26-E</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_id  n_pred  n_gold  precision_full  recall_full  f2_full   AP\n",
       "104  R05-20-E       2       1             0.0          0.0      0.0  0.0\n",
       "105  R05-19-O       1       1             0.0          0.0      0.0  0.0\n",
       "106  R05-27-A       2       1             0.0          0.0      0.0  0.0\n",
       "107  R05-26-I       1       1             0.0          0.0      0.0  0.0\n",
       "108  R05-26-E       1       2             0.0          0.0      0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------\n",
    "# Config: choose max k to evaluate precision@k / recall@k\n",
    "# If None, will use the maximal prediction length in your dataframe.\n",
    "MAX_K = None   # or set e.g. 5 or 10\n",
    "\n",
    "# -----------------------\n",
    "# Helpers\n",
    "def precision_at_k_single(preds, gold_set, k):\n",
    "    \"\"\"Standard precision@k: |relevant in top-k| / k.\n",
    "       If len(preds) < k, missing slots are treated as non-relevant (denominator still k).\n",
    "    \"\"\"\n",
    "    if k <= 0:\n",
    "        return 0.0\n",
    "    topk = preds[:k]\n",
    "    hits = sum(1 for p in topk if p in gold_set)\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k_single(preds, gold_set, k):\n",
    "    \"\"\"Recall@k: |relevant in top-k| / |gold_set|. If gold_set empty -> 0.0.\"\"\"\n",
    "    if len(gold_set) == 0:\n",
    "        return 0.0\n",
    "    topk = preds[:k]\n",
    "    hits = sum(1 for p in topk if p in gold_set)\n",
    "    return hits / len(gold_set)\n",
    "\n",
    "def average_precision(preds, gold_set):\n",
    "    \"\"\"AP: sum_{i:pred_i in gold} (precision@i) / |gold_set| ; returns 0 if gold_set empty.\"\"\"\n",
    "    if len(gold_set) == 0:\n",
    "        return 0.0\n",
    "    hits = 0\n",
    "    sum_precisions = 0.0\n",
    "    for i, p in enumerate(preds, start=1):\n",
    "        if p in gold_set:\n",
    "            hits += 1\n",
    "            sum_precisions += hits / i\n",
    "    if hits == 0:\n",
    "        return 0.0\n",
    "    return sum_precisions / len(gold_set)\n",
    "\n",
    "def f_beta(prec, rec, beta=2.0):\n",
    "    if prec == 0 and rec == 0:\n",
    "        return 0.0\n",
    "    b2 = beta * beta\n",
    "    return (1 + b2) * (prec * rec) / (b2 * prec + rec)\n",
    "\n",
    "# -----------------------\n",
    "# Load gold\n",
    "with open(f\"./kg/data_parsed/{SELECTED_ID}_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    gold = json.load(f)\n",
    "\n",
    "# normalize gold ids to strings\n",
    "for qid, info in gold.items():\n",
    "    gold[qid][\"retrieved_list\"] = [str(x).strip() for x in info.get(\"retrieved_list\", [])]\n",
    "\n",
    "# -----------------------\n",
    "# Prepare preds df (uses in-memory step3_top2_df)\n",
    "preds_df = submission_df.copy()\n",
    "\n",
    "# Ensure preds are lists of strings\n",
    "def ensure_list_of_str(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str(v) for v in x]\n",
    "    if isinstance(x, str):\n",
    "        s = x.strip()\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            # crude parse: split on commas\n",
    "            items = [it.strip().strip(\"'\\\"\") for it in s[1:-1].split(\",\") if it.strip() != \"\"]\n",
    "            return [str(it) for it in items]\n",
    "        return [s]\n",
    "    # fallback\n",
    "    return [str(x)]\n",
    "\n",
    "preds_df[\"preds\"] = preds_df[\"article_id\"].apply(ensure_list_of_str)\n",
    "\n",
    "# Determine K for precision@k / recall@k\n",
    "if MAX_K is None:\n",
    "    max_pred_len = preds_df[\"preds\"].apply(len).max()\n",
    "    # but also consider gold length if you prefer; here we pick max prediction length\n",
    "    K = int(max(1, max_pred_len))\n",
    "else:\n",
    "    K = int(MAX_K)\n",
    "\n",
    "# -----------------------\n",
    "# Evaluate per query\n",
    "rows = []\n",
    "# matrices for precision@k & recall@k\n",
    "prec_at_k_matrix = []  # list of lists per query\n",
    "rec_at_k_matrix = []\n",
    "\n",
    "for _, r in preds_df.iterrows():\n",
    "    qid = r[\"query_id\"]\n",
    "    preds = r[\"preds\"]\n",
    "    gold_list = gold.get(qid, {}).get(\"retrieved_list\", [])\n",
    "    gold_set = set(gold_list)\n",
    "\n",
    "    # overall precision using full predicted list (len(preds) as denom)\n",
    "    full_prec = (sum(1 for p in preds if p in gold_set) / len(preds)) if len(preds) > 0 else 0.0\n",
    "    full_rec = (sum(1 for p in preds if p in gold_set) / len(gold_set)) if len(gold_set) > 0 else 0.0\n",
    "\n",
    "    # F2 using full_prec, full_rec\n",
    "    f2 = f_beta(full_prec, full_rec, beta=2.0)\n",
    "\n",
    "    # AP\n",
    "    ap = average_precision(preds, gold_set)\n",
    "\n",
    "    # precision@k and recall@k for k=1..K\n",
    "    prec_k = [precision_at_k_single(preds, gold_set, k) for k in range(1, K+1)]\n",
    "    rec_k = [recall_at_k_single(preds, gold_set, k) for k in range(1, K+1)]\n",
    "\n",
    "    prec_at_k_matrix.append(prec_k)\n",
    "    rec_at_k_matrix.append(rec_k)\n",
    "\n",
    "    rows.append({\n",
    "        \"query_id\": qid,\n",
    "        \"n_pred\": len(preds),\n",
    "        \"n_gold\": len(gold_list),\n",
    "        \"precision_full\": full_prec,\n",
    "        \"recall_full\": full_rec,\n",
    "        \"f2_full\": f2,\n",
    "        \"AP\": ap\n",
    "    })\n",
    "\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "\n",
    "# -----------------------\n",
    "# Aggregate summary\n",
    "mean_precision_full = df_metrics[\"precision_full\"].mean()\n",
    "mean_recall_full = df_metrics[\"recall_full\"].mean()\n",
    "mean_f2_full = df_metrics[\"f2_full\"].mean()\n",
    "\n",
    "map_all = df_metrics[\"AP\"].mean()\n",
    "map_relevant = df_metrics.loc[df_metrics[\"n_gold\"]>0, \"AP\"].mean()\n",
    "\n",
    "# Precision@k and Recall@k averaged across queries (treating missing preds as non-relevant)\n",
    "prec_at_k_arr = np.mean(np.array(prec_at_k_matrix), axis=0) if len(prec_at_k_matrix)>0 else np.zeros(K)\n",
    "rec_at_k_arr = np.mean(np.array(rec_at_k_matrix), axis=0) if len(rec_at_k_matrix)>0 else np.zeros(K)\n",
    "\n",
    "# -----------------------\n",
    "# Print summary\n",
    "print(\"=== Aggregate retrieval metrics ===\")\n",
    "print(f\"Queries evaluated : {len(df_metrics)}\")\n",
    "print(f\"Mean Precision (full predicted lists) : {mean_precision_full:.4f}\")\n",
    "print(f\"Mean Recall (full predicted lists)    : {mean_recall_full:.4f}\")\n",
    "print(f\"Mean F2 (β=2)                         : {mean_f2_full:.4f}\")\n",
    "print(f\"MAP (all queries; AP=0 for empty)    : {map_all:.4f}\")\n",
    "print(f\"MAP (only queries with >=1 gold)     : {map_relevant:.4f}\")\n",
    "print()\n",
    "print(\"Precision@k (k=1..{}):\".format(K))\n",
    "for k, val in enumerate(prec_at_k_arr, start=1):\n",
    "    print(f\"  P@{k}: {val:.4f}\")\n",
    "print()\n",
    "print(\"Recall@k (k=1..{}):\".format(K))\n",
    "for k, val in enumerate(rec_at_k_arr, start=1):\n",
    "    print(f\"  R@{k}: {val:.4f}\")\n",
    "\n",
    "# -----------------------\n",
    "# Expose results for further inspection\n",
    "# df_metrics contains per-query metrics\n",
    "# prec_at_k_arr and rec_at_k_arr contain averaged P@k / R@k across queries\n",
    "# You can examine per-query AP distribution:\n",
    "df_metrics_sorted = df_metrics.sort_values(\"AP\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# show top/bottom problematic queries\n",
    "print(\"\\nTop 5 queries by AP:\")\n",
    "display(df_metrics_sorted.head(5))\n",
    "print(\"\\nBottom 5 queries by AP (including zero AP):\")\n",
    "display(df_metrics_sorted.tail(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f2</th>\n",
       "      <th>AP</th>\n",
       "      <th>n_gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R06-01-A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R06-01-E</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R06-01-I</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R06-01-O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R06-03-A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>R06-31-U</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>R06-37-A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>R06-37-E</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>R06-37-I</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>R06-37-U</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    query_id  precision  recall        f2    AP  n_gold\n",
       "0   R06-01-A        1.0     1.0  1.000000  1.00       2\n",
       "1   R06-01-E        0.5     1.0  0.833333  1.00       1\n",
       "2   R06-01-I        1.0     1.0  1.000000  1.00       1\n",
       "3   R06-01-O        0.0     0.0  0.000000  0.00       1\n",
       "4   R06-03-A        1.0     1.0  1.000000  1.00       1\n",
       "..       ...        ...     ...       ...   ...     ...\n",
       "78  R06-31-U        1.0     1.0  1.000000  1.00       1\n",
       "79  R06-37-A        1.0     1.0  1.000000  1.00       1\n",
       "80  R06-37-E        0.5     1.0  0.833333  0.50       1\n",
       "81  R06-37-I        1.0     1.0  1.000000  1.00       1\n",
       "82  R06-37-U        0.5     0.5  0.500000  0.25       2\n",
       "\n",
       "[83 rows x 6 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics.head(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
